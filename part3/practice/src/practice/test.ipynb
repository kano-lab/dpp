{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ処理プログラミング 第3回"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Livedoorニュースコーパスで学習されたモデルをもとに、ニュース記事のカテゴリを予測する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/content/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch fugashi ipadic pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータの読み込み\n",
    "- 読み込むファイル\n",
    "    - `test.csv`  \n",
    "    モデルのテストに利用するためのデータ。カラムと内容は以下の通りです。\n",
    "    - label: ニュース記事のカテゴリを表すラベルを数字で表したもの。同じカテゴリーの記事は同じ数字になっています。\n",
    "    - url: ニュース記事のURL\n",
    "    - date: ニュース記事の日付\n",
    "    - category: ニュース記事のカテゴリ\n",
    "    - body: ニュース記事本文\n",
    "- 読み込み後の形式  \n",
    "    以下のような配列形式でデータを読み込んでください。\n",
    "    なお、最終的にデータが格納される配列の変数名は`test_dataset`としてください。\n",
    "    ```\n",
    "    [\n",
    "        {\n",
    "            \"label\": ラベル, \n",
    "            \"text\": ニュース記事本文\n",
    "        },\n",
    "        {\n",
    "            \"label\": ラベル, \n",
    "            \"text\": ニュース記事本文\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 以下にテストデータを上記の形式で読み込むコードを書いてください\n",
    "import pandas as pd\n",
    "df = pd.read_csv(BASE_PATH+'test.csv')\n",
    "test_dataset = []\n",
    "for i in range(len(df)):\n",
    "    label = df.iloc[i, 0]\n",
    "    text = df.iloc[i, 4]\n",
    "    test_dataset.append({\n",
    "        'label': label,\n",
    "        'text': text\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### category情報が格納されたファイルの読み込み\n",
    "- 読み込むファイル\n",
    "    - `categories.json`  \n",
    "    ラベルのカテゴリ情報が格納されたファイル。\n",
    "    以下のような形式でデータが格納されています。\n",
    "    ```\n",
    "    [\n",
    "        {\n",
    "            \"label\": ラベル名(数字),\n",
    "            \"category\": カテゴリ名,\n",
    "        }\n",
    "        ...\n",
    "    ]\n",
    "    \n",
    "    ```\n",
    "- 読み込み後の形式  \n",
    "    そのままのPython dict型の要素が格納された配列で読み込んでください。\n",
    "    配列が格納される変数名は`categories`としてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 以下にcategory情報を上記の形式で読み込むコードを書いてください\n",
    "import json\n",
    "with open(BASE_PATH+'categories.json') as f:\n",
    "    categories = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed値の設定\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: トークナイザを読み込むコードを書いて下さい。\n",
    "# トークナイザは「'cl-tohoku/bert-base-japanese-whole-word-masking'」用のモデルを利用して下さい。この名称+tokenizer等で検索するか、学習スクリプトを参考にしてみて下さい。\n",
    "# なお、読み込んだtokenizerはtokenzierという変数に格納して下さい。\n",
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_max_length = tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: test_datasetの各辞書型のデータをfor文で回し、辞書型のデータ内の'text'キーの値をトークナイザに入力し、その結果を元の辞書型のデータに'encoding'キーで追加してください。\n",
    "# tokenizerに渡すパラメーターは以下のものを利用して下さい。\n",
    "# padding='max_length', truncation=True, max_length=model_max_length, return_tensors='pt'\n",
    "for data in test_dataset:\n",
    "    data['encoding'] = tokenizer(data['text'], padding='max_length', truncation=True, max_length=model_max_length, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 3, 'text': 'ソニープロフェッショナルセミナー〜3Dの世界【ビデオSALON】【開催概要】◎ソニープロフェッショナルセミナー\\u3000〜複眼カムコーダーとVEGASで3Dの世界へ〜 開催-----------------------------------------------------------------------3Dカムコーダーの登場でより簡単に3D撮影ができるようになったとはいえ、3Dの基礎を知っているのとそうでないのとでは撮影映像の質も違ってくるはず。3Dに興味のある方、実際にこれから3D制作に携わっていく方を対象とした入門編。◇日時：2012年3月7日(水) 13:00〜15:00◇会場：ソニー株式会社 本社（JR品川駅港南口）◇入場：無料（定員50名）\\u3000※事前申込が必要です。申込締切3/6(火)\\u3000※定員になり次第、締め切らせていただきます。▼お申し込みはこちらhttp://www.sony.jp/professional/event/info/pb20120307.html■ビデオSALON 最新記事・ニコニコ動画、生中継用エンコーダーや画質向上など新サービスを続々発表・ふるいちやすし氏の新作上映とトークイベントをアップルストアで開催・ブラックマジックデザイン、Thunderbolt対応のIntensity Shuttleを発売・TVF2012の入賞30作品が決定■ビデオSALON最新号    ■関連記事・寝つけない夜に寝室で愛用…滝クリもオススメのスマートAVライフはパナソニックでチェック【話題】・ついにケーブル不要？ 無線での高速データ送受信実現か\\u3000東京工業大学とソニーが世界最高速のミリ波無線用LSIを共同開発【ビデオSALON】・東電リストラ！\\u3000クビを切られたのは人気キャラクター「でんこちゃん」だった【話題】・家庭菜園の流行で注目！\\u3000初心者や女性にもぴったりな軽くて使いやすい「ミニ耕運機\\u3000ＬＧＣ１２０」【売れ筋チェック】・「最新」とつぶやくだけで最新ニュースをゲット！\\u3000定期配信も可能な便利機能が「LINE」に登場【話題】', 'encoding': {'input_ids': tensor([[    2,  6369,  2496,  1050, 19041, 21146,   590,  1143,    48,   300,\n",
      "             5,   324,  9680,  3030, 10740, 28743,  2345,  9594,  9680,   682,\n",
      "         14159,  9594,     1,  6369,  2496,  1050, 19041, 21146,   590,  1143,\n",
      "           990, 29919,  7889, 21880,    13,   676, 13782,  2541,    12,    48,\n",
      "           300,     5,   324,   118,  1143,   682,    61,    61,    61,    61,\n",
      "            61,    61,    61,    61,    61,    61,    61,    61,    61,    61,\n",
      "            61,    61,    61,    61,    61,    61,    61,    61,    61,    61,\n",
      "            61,    61,    61,    61,    61,    61,    61,    61,    61,    61,\n",
      "            61,    61,    61,    61,    61,    61,    61,    61,    61,    61,\n",
      "            61,    61, 24282, 28573, 28573, 28573, 28573, 28573, 28573, 28573,\n",
      "         28573, 28573, 28573, 28573, 28573, 28573, 28573, 28573, 28573, 28573,\n",
      "         28573, 28573, 28573, 28573, 28573, 28573,    48,   300,  7889, 21880,\n",
      "             5,   656,    12,   221,  5880,     7,    48,   300,  1698,    14,\n",
      "           392,   124,     7,    58,    10,    13,     9,  4422,     6,    48,\n",
      "           300,     5,  2883,    11,  4021,    16,    33,     5,    13,  1778,\n",
      "            12,    80,     5,    13,    12,     9,  1698,  2148,     5,  2015,\n",
      "            28,  8652,    16,  2501,  4627,     8,    48,   300,     7,  4878,\n",
      "             5,    31,   283,     6,  1379,     7, 13162,    48,   300,  1079,\n",
      "             7,  8259,    16,   861,   283,    11,  1471,    13,    15,    10,\n",
      "          7814,   512,     8,     1, 23413,   266,   908,    19,    48,    37,\n",
      "           127,    32,    23,   326,    24,   483,   266,  1999,  1143,   330,\n",
      "           266,  1999,     1,  3821,   266,  6369,  1275,  2557,    23,  1766,\n",
      "         10444,   235,  1752, 28769,  1285,     1,  7538,   266,  4691,    23,\n",
      "          9545,  1241,   125,    24,  3328,  6325,  2177, 29024,    14,   727,\n",
      "          2992,     8,  2177, 29024,  3412, 29042,    48,   465,   101,    23,\n",
      "          1183,    24,  3328,  9545,     7,   297,  3847,     6,  9783,  8932,\n",
      "           191,    16, 23466, 28512,  2610,     8,     1,    73, 24551,     9,\n",
      "          4871, 21313, 16831, 21749,   143,   936, 13882,   143, 18453,   465,\n",
      "          9856, 28890,  3865, 18586,   465,  3152, 26014,   465,  2747, 28890,\n",
      "         28538,   465,  1547, 28896,   908, 28464, 17904, 28509,   143,  1868,\n",
      "         28566, 28600, 28595, 25035,  3030, 10740, 28743,  2345,  6215,  2622,\n",
      "            35, 12192,  4884,     6,   128,  2443,   241,  2411, 21880,    49,\n",
      "         23882,  2771,    64,   147,  1645,    11, 21080,   602,    35,  8491,\n",
      "          3474,  2076, 28454,   643,     5,  8448,  4761,    13,  5298,  1989,\n",
      "            11, 10290, 10192,    12,   682,    35,  4035, 28523, 17394, 16055,\n",
      "             6,  4996,  7274,   275,  9736, 28595, 28566,  1277,     5, 14513,\n",
      "          6679,  4976,  4696,  2480, 28566,   944,    11,   580,    35,  3700,\n",
      "         28718,   908,     5,  7022,   525,   403,    14,  1067, 25035,  3030,\n",
      "         10740, 28743,  2345,  6215,   365, 25035,  1634,  2622,    35,  4492,\n",
      "          2836,    80,  1563,     7,  4492,  1157,    12, 20457,  3215,  5146,\n",
      "          3023,    28,  3148, 28466, 28542,     5,  6724,  6171,  6890,     9,\n",
      "         15118,    12,  9398,  9680,  4459,  9594,    35,  5995,  6418,  9191,\n",
      "          2935,  4517,    12,     5,  1942,  1676,  1104, 28725, 28836,  2519,\n",
      "            29, 24410,    13,  6369,    14,   324,  1337,  1463,     5,  8191,\n",
      "          2058,  4517,   241, 15662, 28645,    11,  1683,   530,  9680,  3030,\n",
      "         10740, 28743,  2345,  9594,    35,   122, 28783,  3826, 28485,   679,\n",
      "         13700,    11, 19962,    20,    10,     5,     9,  1571,  1480,    36,\n",
      "          7249,    27,  4187,    38,   308,    10,  9680,  4459,  9594,    35,\n",
      "          3290,  9541, 29013,     5,  4697,    12,  2906,   679, 16842,    49,\n",
      "           969,     7,    28, 10411, 21087,    18, 15883,    16,  3276,  3428,\n",
      "            36,  3568,  7672, 28771, 28639, 21156, 28598,  4970,    38,  9680,\n",
      "          9317,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# データセットの確認\n",
    "print(test_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境の設定\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルの読み込み\n",
    "from transformers import BertForSequenceClassification\n",
    "import torch\n",
    "model_path = BASE_PATH+'model/model.pth'\n",
    "model = BertForSequenceClassification.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', num_labels=len(categories))\n",
    "# 学習済みモデルの重みを読み込む\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval() # モデルを評価モードにする\n",
    "model.to(device) # モデルをGPUに載せる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータのDataLoaderを作成\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 738/738 [00:47<00:00, 15.48it/s] \n"
     ]
    }
   ],
   "source": [
    "# 評価用のスクリプト\n",
    "from tqdm import tqdm\n",
    "texts = []\n",
    "pred_labels = []\n",
    "true_labels = []\n",
    "for data in tqdm(test_dataloader):\n",
    "    label = data['label']\n",
    "    encoding = data['encoding']\n",
    "    output = model(**{k: v.squeeze(0).to(device) for k, v in encoding.items()})\n",
    "    \n",
    "    pred_label = torch.argmax(output.logits, dim=1)\n",
    "    pred_labels.append(pred_label.item())\n",
    "    true_labels.append(label)\n",
    "    texts.append(data['text'])\n",
    "assert len(pred_labels) == len(true_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9525745257452575\n"
     ]
    }
   ],
   "source": [
    "accuracy = (torch.tensor(pred_labels) == torch.tensor(true_labels)).float().sum().item() / len(true_labels)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ['ソニープロフェッショナルセミナー〜3Dの世界【ビデオSALON】【開催概要】◎ソニープロフェッショナルセミナー\\u3000〜複眼カムコーダーとVEGASで3Dの世界へ〜 開催-----------------------------------------------------------------------3Dカムコーダーの登場でより簡単に3D撮影ができるようになったとはいえ、3Dの基礎を知っているのとそうでないのとでは撮影映像の質も違ってくるはず。3Dに興味のある方、実際にこれから3D制作に携わっていく方を対象とした入門編。◇日時：2012年3月7日(水) 13:00〜15:00◇会場：ソニー株式会社 本社（JR品川駅港南口）◇入場：無料（定員50名）\\u3000※事前申込が必要です。申込締切3/6(火)\\u3000※定員になり次第、締め切らせていただきます。▼お申し込みはこちらhttp://www.sony.jp/professional/event/info/pb20120307.html■ビデオSALON 最新記事・ニコニコ動画、生中継用エンコーダーや画質向上など新サービスを続々発表・ふるいちやすし氏の新作上映とトークイベントをアップルストアで開催・ブラックマジックデザイン、Thunderbolt対応のIntensity Shuttleを発売・TVF2012の入賞30作品が決定■ビデオSALON最新号    ■関連記事・寝つけない夜に寝室で愛用…滝クリもオススメのスマートAVライフはパナソニックでチェック【話題】・ついにケーブル不要？ 無線での高速データ送受信実現か\\u3000東京工業大学とソニーが世界最高速のミリ波無線用LSIを共同開発【ビデオSALON】・東電リストラ！\\u3000クビを切られたのは人気キャラクター「でんこちゃん」だった【話題】・家庭菜園の流行で注目！\\u3000初心者や女性にもぴったりな軽くて使いやすい「ミニ耕運機\\u3000ＬＧＣ１２０」【売れ筋チェック】・「最新」とつぶやくだけで最新ニュースをゲット！\\u3000定期配信も可能な便利機能が「LINE」に登場【話題】']\n",
      "model output: {'label': 3, 'category': 'kaden-channel'}\n",
      "True label: {'label': 3, 'category': 'kaden-channel'}\n",
      "\n",
      "Text: ['レディー・ガガに並んだ！\\u3000グーグルが選んだ初の日本人アーティストは“バーチャルアイドル”「初音ミク」─\\u3000「Chrome」CMに出演中【話題】グーグルの「Google Chromeグローバルキャンペーン」の新CMが、16日よりオンエアを開始した。今回初めて、日本人アーティストが出演したのだが、なんとそれは“バーチャルアイドル”として高い人気を誇る「初音ミク」だった。いままで、レディー・ガガやジャスティン・ビーバーといった大物歌手ばかり出演の、このCMにバーチャルアイドルの登場ということで、大きな話題になっている。初音ミクは、クリプトン・フューチャー・メディアが開発したミュージック・ソフトウェア。知らない人も多いかもしれないが米国iTunesのワールドチャートでも、アルバム『supercell』が1位を獲得しているなど彼女は国外でも人気なのだ。日本のキャラクター文化への人気や海外からの評価はやはり高いと再認識させられる話題である。Google「Chrome」の新CM、“初音ミク”が登場……初の日本代表アーティスト    ■関連記事・「老後どうすんの？」さんまの質問にメッシが激怒！\\u3000テレビが凍りついた瞬間【話題】・北朝鮮の朝鮮中央テレビが「金正日総書記死去」と報道\\u3000【速報】・高橋名人も苦言！\\u3000買ったばかりのPS Vitaがトラブル続きで不満殺到【話題】・「PS Vita」がついに発売\\u3000—\\u3000初日は待ちわびたファンが行列を作る大盛況【話題】・携帯電話がお手柄！泥棒の携帯電話が偶然警察に電話をかけ、逮捕へ【話題】']\n",
      "model output: {'label': 3, 'category': 'kaden-channel'}\n",
      "True label: {'label': 3, 'category': 'kaden-channel'}\n",
      "\n",
      "Text: ['シャープ、7インチAndroidタブレット「GALAPAGOS」シリーズ2製品を6月27日からAndroid 4.0へのOSバージョンアップを提供EB-A71GJ-BおよびEB-W700GがAndroid 4.0 ICSに！ シャープは14日、現在販売中の7インチサイズのメディアタブレットのうちモバイルWiMAXに対応した「EB-A71GJ-B」およびWi-Fi対応法人向け「EB-W700G」の2機種においてAndroid 4.0（開発コード名：IceCream Sandwich；ICS）へのOのバージョンアップを含むソフトウェア更新を2012年6月27日（火）から提供開始すると発表しています。このソフトウェア更新によってOSバージョンが最新のAndroid 4.0にバージョンアップするほか、ユーザーインターフェースや各種機能の強化が行われるということです。なお、イー・アクセスからイー・モバイル向けとして販売されている「GALAPAGOS A01SH」にも同様のソフトウェア更新が提供される予定とのこと。ただし、こちらは別途イー・モバイルから近日中に案内されるということです。ソフトウェア更新の内容は以下の通りです。ソフトウェア更新の方法などの詳細については、別途シャープのWebページおよびメディアタブレットサポートページで案内するとしています。「Android 4.0」によるユーザーインターフェース／機能の強化基本的な操作方法、標準搭載アプリが Android 4.0 の仕様に応じたものとなります。ただし、 Android 4.0 の機能の内、ハードウェアの仕様に依存するため使用できないものがあります。● 主な変更点・ロック画面から直接カメラアプリを起動できるようになります。・ロック画面の通知表示から各アプリを直接起動できるようになります。・カメラアプリに顔を変形させる動画撮影やパノラマ撮影（静止画）などの機能が加わります。・ホーム画面に表示されるアイコンを重ねることで、フォルダ化できるようになります。・マルチタスクで選択できるアプリを、簡単に削除できるようになります。・ウィジェット対応アプリが追加されます。（ギャラリー、電源管理 など）・ブラウザが強化されます。（オフラインで読めるよう保存する機能や、デスクトップ版のホームページをリクエストする機能など）・microSD™ メモリーカード内のメディアファイルに、直接アクセスできるようになります。・スクリーンショット撮影機能が追加されます。ご利用いただけなくなる機能Android 4.0 では、microSDメモリーカード内のファイルに直接アクセスできるようになりますが、これに伴い、従来の「ファイルブラウザ」は廃止されます。Google Play ストア にてファイル操作ができるツールを適宜ダウンロードしてご利用ください。※お客様がご自身でインストールされたアプリケーションの Android™ 4.0 での動作については、各アプリベンダーにお尋ねくださ液晶テレビAQUOSとの連携機能を追加当社製スマートフォンで提供している「Smart Familink」機能※1を新たに提供いたします。（一部機能はご利用になれません）この機能によりメディアタブレットをAQUOS※2と連携させることができ、活用シーンがさらに拡がります。● 主な提供機能・メディアタブレットに保存した静止画※3、動画※3、音楽※3をAQUOS※2の大画面やスピーカーで視聴する機能・タブレットで閲覧しているWebサイトのアドレス（URL）をAQUOSに送り、AQUOSの大画面でWebサイトをご覧いただく機能※4・ネットワークストレージ※5に保存した静止画※3、動画※3、音楽※3をタブレットで視聴する機能※1 スマートフォンでの提供機能のうち、以下の機能は提供されません。\\u3000\\u3000・AQUOSインフォメーション機能（メディアタブレットへのメール着信を、視聴中のAQUOSの画面にお知らせする機能）\\u3000\\u3000・AQUOSブルーレイに保存されている動画（録画されたコンテンツも含む）や静止画、音楽をメディアタブレットで視聴したり、AQUOSに移動させたり、AQUOSで視聴する機能。 ※2 AQUOS対応機種についての最新の情報は、「スマートファミリンク」サポートホームページをご覧ください。※3 タブレットで撮影した動画（MP4／3gp）、メディアタブレットで撮影した静止画（JPEG）、MP3形式の音楽が再生可能。著作権保護された動画やPCなどで加工した写真の一部や解像度によっては再生表示できません。※4 タブレットで閲覧しているWebサイトと同一のWebサイトが表示されないことがあります。※5 対応するネットワークストレージについては、メディアタブレットサポートホームページにてご案内する予定です。記事執筆：memn0ck■関連リンク・エスマックス（S-MAX）・エスマックス（S-MAX） smaxjp on Twitter・Android™ 4.0 へのシステム更新について | GALAPAGOS（ガラパゴス）：シャープ・GALAPAGOSメディアタブレット ポータルサイト']\n",
      "model output: {'label': 6, 'category': 'smax'}\n",
      "True label: {'label': 6, 'category': 'smax'}\n",
      "\n",
      "Text: ['美しさが際立つ新Xperiaが発売へ！ドコモ、Xperia NX SO-02Dが凄いドコモは、グローバルフラッグシップモデルにふさわしいシンプルなフォルムのデザインと、透明素材「Floating Prism」をアクセントにした美しさが際立つ4.3インチHD液晶を搭載したスマートフォン「docomo NEXT series Xperia NX SO-02D」を2012年2月24日より発売すると発表した。「Xperia NX SO-02D」は、ハイスペック&エンタテインメント機能が充実したスマートフォンだ。高性能のCPU搭載により、HD動画やグラフィカルなWebサイトなどのリッチなコンテンツをサクサク軽快に閲覧できる。グローバルフラッグシップモデルにふさわしいデザインと美しさが際立つ4.3インチHD液晶を備える。ボディのクリアな“Floating Prism（フローティングプリズム）”は、着信時や操作時にLEDの静かな輝きを放ち、3つのアイコンが浮かび上がる仕様だ。解像感の高い写真撮影、撮影スピードも劇的に進化した高感度カメラであり、有効約1210万画素のソニー製裏面照射型CMOSセンサー“Exmor R for mobile”と、ソニー・エリクソン独自の画像エンジンを搭載した。■「docomo NEXT series Xperia NX SO-02D」製品情報■ドコモ■ドコモに関連した記事をもっと見る・ドコモ7.8mmの有機ELスマホ開発！スリムボディのスマートフォン「docomo NEXT series P-04D」・ついに発売日が決定！ドコモのディズニースマホ「F-08D」の魅力をさぐる・発売前に実機をチェック！ソニー・エリクソン、「Xperia NX SO-02D」を先行展示・ドコモ、4機種の機能バージョンアップを実施Transcend SDHCカード 16GB Class10 永久保証 [フラストレーションフリーパッケージ (FFP)] TS16GSDHC10Eトランセンド・ジャパン販売元：Amazon.co.jpクチコミを見る']\n",
      "model output: {'label': 7, 'category': 'it-life-hack'}\n",
      "True label: {'label': 7, 'category': 'it-life-hack'}\n",
      "\n",
      "Text: ['「SATC」のキャリー風にセクシーに決めた森泉のタイプは“エイダン”\\u3000ニューヨークを舞台に4人の洗練されたファッションと、センセーショナルなガールズトークが人気の海外ドラマ「セックス・アンド・ザ・シティ」。劇場版第2弾である「セックス・アンド・ザ・シティ2」は、全世界で興行収入を4億ドルを記録して大ヒットを記録しました。主演の4人であるサラ・ジェシカ・パーカー、キム・キャトラル、クリスティン・デイヴィス、シンシア・ニクソンが揃っての初来日を果たし、“SATC旋風”が巻き起こったのは記憶に新しいですよね。\\u3000ファン待望のブルーレイ&DVDセットは10月27日にリリース、それを記念したガールズパーティが22日都内で開催されました。イベントには、限定30名のSATCファンの一般女性が招待され、ゲストにはモデルの森泉さん、MCにはLiLiCoさんと“SATCフリーク”の2名が登場しました。一般招待客が入場すると、ウェルカムドリンクとしてモエ・エ・シャンドンが振る舞われ、イベント開始前から会場は華やかなムードに包まれました。\\u3000「芸能界1SATCが好きといっても過言じゃない」と話す森さんは、「今日のファッションポイントは…キャリー風にしてきた。色がかわいいし、意外とセクシーでしょ。靴もキラキラなの」と、ゴールドのJIMMY CHOO（ジミーチュウ）のハイヒールに、メーガンのピンク＆スパンコールミニドレスを披露してくれました。\\u3000SATC2に登場するファッションが、実は日本の影響を受けているというエピソードを知ると、「とても誇りに思います。一番のお気に入りは、キャリーがスークで着ているファッションかな。ピチピチのTシャツにふんわりしたスカートで。意外な組み合わせだけど、すごくマッチしてる。SATCは本当にファッションが参考になる」とDVDを見ながら一時停止して、自分のワードローブを探して真似できないか研究している、というエピソードも披露し、本作もブルーレイ＆DVDで何度も観ることを宣言していました。\\u3000SATCといえば、恋。ということで、好きな男性像に話題が及ぶと「好きな男性のタイプはエイダンみたいな人。昔から顔がタイプ！！」数多く出てくるSATCシリーズの中でもエイダンが昔から好きだそうで、「昔から仲いい友達が4人くらい？いて、よく（SATCみたいに）オシャレの話とか恋の相談もよくするの。オシャレな友達がいるっていいよね」と普段からガールズトークで盛り上がることを語ってくれました。\\u3000最後に、作品の感想を聞かれると「この作品は、ファッションも生き方もインテリアも勉強になる作品ですよね。男性が見ても勉強になるかも」とコメント。\\u3000今回の初回限定コレクターズ・エディションは、ファンにはお馴染みの世界的デザイナーChristian Lacroix（クリスチャン・ラクロワ）デザインによる超豪華BOX豪華仕様。さらに、SATCの舞台裏や華麗なるオトコたちなど約83分にも及ぶ超豪華映像特典が収録されている他、フォトブックや特製ボックスなどもついているので、女性のオシャレ心もくすぐる貴重なBOXとなっていますので、改めて日本に影響されたというファッションを楽しむのはいかがですか？「セックス・アンド・ザ・シティ2」ストーリー友人の結婚式で、久しぶりに顔をそろえた4人の親友たち。ベストセラー作家のキャリー(サラ・ジェシカ・パーカー)は、2年前に波乱の末に結ばれたミスター・ビッグ(クリス・ノース)と、平和な結婚生活を送っていた。PR 会社社長のサマンサ(キム・キャトラル)は、自ら選んだ独身生活を謳歌していた。優しい夫と可愛い子供に囲まれたシャーロット(クリスティン・デイビス) は、理想の家庭作りを楽しんでいた。弁護士のミランダ(シンシア・ニクソン)は、キャリアと家庭の両立に励んでいた——。そんなキャリーが結婚生活に疑問を抱くようになったのは、ミスター・ビッグとの結婚記念日だった。・セックス・アンド・ザ・シティ2 - 作品情報']\n",
      "model output: {'label': 1, 'category': 'peachy'}\n",
      "True label: {'label': 1, 'category': 'peachy'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 実際に予測されたラベルと正解ラベルを表示\n",
    "for i in range(5):\n",
    "    print(f\"Text: {texts[i]}\")\n",
    "    print(f\"model output: {categories[pred_labels[i]]}\")\n",
    "    print(f\"True label: {categories[true_labels[i]]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2(デコーダーモデル)を触ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(32000, 1024)\n",
       "    (wpe): Embedding(1024, 1024)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-23): 24 x GPT2Block(\n",
       "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2SdpaAttention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"rinna/japanese-gpt2-medium\", use_fast=False)\n",
    "gpt_tokenizer.do_lower_case = True  \n",
    "\n",
    "decoder_model = AutoModelForCausalLM.from_pretrained(\"rinna/japanese-gpt2-medium\")\n",
    "decoder_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章生成時のパラメータ\n",
    "# TODO: パラメーターの値を変えたり追加したりして、モデルの出力がどのように変化するかをみてみましょう。各種パラメーターがどのような働きなのかを理解しながら変えてみるのが良いかもしれません。\n",
    "params = {\n",
    "    \"max_length\":100,\n",
    "    \"top_k\" : 50,\n",
    "    \"temperature\": 0.7,\n",
    "    \"do_sample\": True,\n",
    "    # \"num_beams\":5,\n",
    "    # \"early_stopping\":True,\n",
    "    # \"no_repeat_ngram_size\":2,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "昔々あるところに、おじいさんとおばあさんが住んでいました。 おじいさんはいつもお店番をしていて、おばあさんはおじいさんの家に遊びに行っていました。 でもおばあさんは、いつもおじいさんと一緒にいるので、だんだんとおじいさんのことが嫌いになっていきました。 おじいさんは、おじいさんの家に遊びに行ったとき、何だかお腹\n"
     ]
    }
   ],
   "source": [
    "# NOTE: start_textを色々変えてみると...?????\n",
    "start_text = \"昔々あるところに、\"\n",
    "with torch.no_grad():\n",
    "    input_ids = gpt_tokenizer.encode(start_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "    output_ids = decoder_model.generate(input_ids.to(device), pad_token_id=gpt_tokenizer.pad_token_id, **params)\n",
    "\n",
    "print(gpt_tokenizer.decode(output_ids.tolist()[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
