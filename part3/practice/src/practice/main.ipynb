{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livedoorニュースコーパスを用いたニューストピック分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Livedoorニュースコーパスのダウンロードと展開"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-10 13:37:08--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
      "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
      "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8855190 (8.4M) [application/x-gzip]\n",
      "Saving to: ‘ldcc-20140209.tar.gz.1’\n",
      "\n",
      "ldcc-20140209.tar.g 100%[===================>]   8.44M  15.1MB/s    in 0.6s    \n",
      "\n",
      "2024-07-10 13:37:09 (15.1 MB/s) - ‘ldcc-20140209.tar.gz.1’ saved [8855190/8855190]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.rondhuit.com/download/ldcc-20140209.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tarfile\n",
    "\n",
    "# ファイルパスを指定する\n",
    "tar_file_path = \"./content/ldcc-20140209.tar.gz\"\n",
    "extract_folder = \"./content/ldcc_data/\"\n",
    "\n",
    "# tar.gzファイルを解凍し、extract_folderに格納する\n",
    "with tarfile.open(tar_file_path, \"r:gz\") as tar:\n",
    "    tar.extractall(path=extract_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_articles_from_directory(directory_path):\n",
    "    #ディレクトリーの中から記事のテキストファイルのパスをリストとして読み込む\n",
    "    files = [f for f in os.listdir(directory_path) if f not in [\"LICENSE.txt\"]]\n",
    "    \n",
    "    articles = []\n",
    "    for file in files:\n",
    "        #記事を一つずつ読み込み、url,date,bodyに分け、辞書を作る\n",
    "        with open(os.path.join(directory_path, file), \n",
    "\t\t\"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            articles.append({\n",
    "                \"url\": lines[0].strip(),\n",
    "                \"date\": lines[1].strip(),\n",
    "                \"body\": ''.join(lines[2:]).strip().replace('\\n','')\n",
    "            })\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movie-enter': './content/csv/movie-enter.csv', 'it-life-hack': './content/csv/it-life-hack.csv', 'kaden-channel': './content/csv/kaden-channel.csv', 'topic-news': './content/csv/topic-news.csv', 'livedoor-homme': './content/csv/livedoor-homme.csv', 'peachy': './content/csv/peachy.csv', 'sports-watch': './content/csv/sports-watch.csv', 'dokujo-tsushin': './content/csv/dokujo-tsushin.csv', 'smax': './content/csv/smax.csv'}\n"
     ]
    }
   ],
   "source": [
    "# 各記事のディレクトリーを取得する\n",
    "directories = [d for d in os.listdir(extract_folder + \"text/\") \n",
    "\tif d not in [\"CHANGES.txt\", \"README.txt\"]]\n",
    "\n",
    "# カテゴリーごとのCSVファイルを作る\n",
    "csv_file_paths = {}\n",
    "for directory in directories:\n",
    "    # Read articles from the category directory\n",
    "    articles = read_articles_from_directory(extract_folder + \"text/\" + directory)\n",
    "    df = pd.DataFrame(articles)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_path = f\"./content/csv/{directory}.csv\"\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    csv_file_paths[directory] = csv_path\n",
    "\n",
    "print(csv_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 0, 'category': 'topic-news.csv'}, {'label': 1, 'category': 'dokujo-tsushin.csv'}, {'label': 2, 'category': 'livedoor-homme.csv'}, {'label': 3, 'category': 'it-life-hack.csv'}, {'label': 4, 'category': 'peachy.csv'}, {'label': 5, 'category': 'kaden-channel.csv'}, {'label': 6, 'category': 'smax.csv'}, {'label': 7, 'category': 'sports-watch.csv'}, {'label': 8, 'category': 'movie-enter.csv'}]\n"
     ]
    }
   ],
   "source": [
    "categories = [{\"label\":index,\"category\":name} for index,name in enumerate(os.listdir(\"./content/csv/\"))]\n",
    "num_labels = len(categories)\n",
    "print(categories)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/mizuki/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# 必要なモジュールのインポート\n",
    "!pip install transformers torch \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=9, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', num_labels=num_labels)\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fugashi\n",
      "  Downloading fugashi-1.3.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Collecting ipadic\n",
      "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hDownloading fugashi-1.3.2-cp312-cp312-macosx_11_0_arm64.whl (512 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.6/512.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: ipadic\n",
      "  Building wheel for ipadic (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=28af2c2db0c754a8ca50a4917c35426842a6928c86f756ada6091cba648bbf3e\n",
      "  Stored in directory: /Users/mizuki/Library/Caches/pip/wheels/93/8b/55/dd5978a069678c372520847cf84ba2ec539cb41917c00a2206\n",
      "Successfully built ipadic\n",
      "Installing collected packages: ipadic, fugashi\n",
      "Successfully installed fugashi-1.3.2 ipadic-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# tokenizerに必要なモジュールのインポート\n",
    "!pip install fugashi ipadic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizerの読み込み\n",
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing topic-news.csv...\n",
      "Processing dokujo-tsushin.csv...\n",
      "Processing livedoor-homme.csv...\n",
      "Processing it-life-hack.csv...\n",
      "Processing peachy.csv...\n",
      "Processing kaden-channel.csv...\n",
      "Processing smax.csv...\n",
      "Processing sports-watch.csv...\n",
      "Processing movie-enter.csv...\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "row_dataset = []\n",
    "for category in categories:\n",
    "    print(f\"Processing {category['category']}...\")\n",
    "    df = pd.read_csv(f\"./content/csv/{category['category']}\")\n",
    "    for i, row in df.iterrows():\n",
    "        row_dataset.append({\n",
    "            \"text\": row[\"body\"],\n",
    "            \"label\": category[\"label\"],\n",
    "            \"inputs\": tokenizer(row[\"body\"], max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        })\n",
    "random.shuffle(row_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 7367\n",
      "Sample 0: {'text': '嫉妬で彼を束縛していませんか？彼の行動が気になる。携帯が繋がらなければなおのこと。心配が不安になるのは、愛しているがゆえに妄想を働かせるからだ。「彼と連絡がとれないときは、不安で朝まで眠れないんです」という萌さん(27歳)。彼は会社の同期、イベント好きでリーダー的存在だという。「休日になると仲間を集めてバーベキューや飲み会をするんです。カップル以外の男女も参加するのですが、彼はいつも女の子たちにすごく気を使って、必要以上に笑顔を見せたり、髪型とか服装とか私の前でも平気で褒めています。女の子を口説いているわけじゃないとは分かっていても、つい悔しくて眉間に皺が寄ったり不機嫌になったり…。彼からはもう少し大人になれといわれるんですけど」萌さんは彼が好きでたまらないから嫉妬をするのだけど、「実はイベントにも参加する社内の女子社員が彼のことを好きなんです。その子が私のことを『どうしてあんな女が彼女なの』って陰口を叩いているのが耳に入ってしまって」「自分に自信がないから不安でたまらない」と萌さんは嘆く。略奪婚が横行している世の中だ。彼女がいる男に平気で手を出す女性もいる。でも彼女がジタバタしては略奪女の思いのまま。ここは彼のいうように大人になって、余裕の笑みを浮かべ、彼の良きパートナーとして堂々と振る舞ってはいかがだろうか？ 公式の彼女と認められれば社内のこと、そう易々と彼も他の女性の誘いに乗ったりはできないと思うのだが。恋愛をすると彼だけしか見えなくなる。四六時中彼のことを考えて、仕事も趣味も手につかないことは誰もが一度は経験があるだろう。「以前は嫉妬の塊でした」というのはインテリアショップ勤務の礼さん(38歳)。「彼の携帯チェックもしたし、男友達と出かけるときも『誰とどこへ行ったのか』は必ず聞いたし、出張先のホテルに突然押しかけたこともありました」礼さんの異常な嫉妬に彼も辟易していたようだったが、「勤務先の店長が突然病気になり、私が店長代理を任されたんです。今まで彼のことばかり考えていたのに、彼のことを考える暇もなくなりました。仕事をやらざるをえなくなったので」店長が復帰するまでの3か月、礼さんは彼とまともにデートもできなかった。夕食を食べてまた職場に戻ったり、休日も仕事。彼の方が心配をして店に様子を見にきたりしたそうだ。今、礼さんは副店長になり仕入れを任されている。「彼は仕事を頑張っている今の私の方が魅力的だといってくれました。嫉妬していたころの自分は、自分に自信がなくて、彼の周りには魅力的な女性もいたから、いつ彼が私から離れていくか不安だったんです。それで嫉妬して、毎晩彼に電話をして部屋にいることを確認したり、昨夜はどうしていたのか朝メールをしたり、彼を縛りつけようとしたのですね。自分に自信ができれば嫉妬などしなくなりました。『たまには私以外の女性とご飯でも食べてきたら』などと余裕の発言はまだできませんが(笑)」いくら好きでも四六時中一緒に居れば飽きる。それよりもお互いの世界を持ち、知らないことを教えあったり、補える関係でいた方が居心地がいいことが分かったという。子どもの頃、帰りが遅くなると「どこへいっていたの？」「誰と遊んでいたの？」と親から聞かれ、うっとうしい思いをしたことがないだろうか？ 子どもでも束縛されるのはうっとうしいのだ。成人男性ならなおのこと。彼のことが気になって仕方がないのはわかるけど、恋愛を長続きさせるには、いつもべったりよりは程よい距離間は保っていたほうがいい。彼を信じて彼を愛して自分のことも愛そう。嫉妬で自分の心が壊れてしまってはいい恋愛などできない。何事も腹八分目。愛も八分目が長続きするコツのようだ。（オフィスエムツー／佐枝せつこ）', 'label': 1, 'inputs': {'input_ids': tensor([[    2, 20138,    12,   306,    11, 27112,    15,    16,    21,  6769,\n",
      "          1058,    29,  2935,   306,     5,  1891,    14,   704,     7,   139,\n",
      "             8,  4443,    14,  3510,   718,  1860,   312,   521, 28444, 15076,\n",
      "             8, 11386,    14,  4755,     7,   139,     5,     9,     6, 11716,\n",
      "            16,    33,    14, 18918, 20051,    11,  2131, 26536,    40,    75,\n",
      "             8,    36,   306,    13,  2986,    14, 19874,    80,   900,     9,\n",
      "             6,  4755,    12,   599,   126,  8263, 28461,    80,  1058,  2992,\n",
      "            38,   140, 12653,  2375,    23,   971,   573,   258,   306,     9,\n",
      "           811,     5,  5350,     6,  1989,  3596,    12,  5201,    81,   451,\n",
      "            75,    13,   625,     8,    36,  8405,     7,   139,    13,  3587,\n",
      "            11,  2505,    16,  1813, 28633,  8999,    49,  9346,   136,    11,\n",
      "            34,  1058,  2992,     8, 15555,  1000,     5,  5523,    28,   651,\n",
      "            34,     5,  2992,    14,     6,   306,     9,  9749, 11768,   558,\n",
      "             7, 14993, 28504,   704,    11,  2110,    16,     6,   727,   695,\n",
      "             7, 18802,    11,  2685,   790,     6, 22981, 10294, 13085, 10294,\n",
      "          1325,     5,   174,   962,   223, 28781,    12, 26527,    16,    21,\n",
      "          2610,     8, 11768,    11,  1285, 28900, 28457,    16,    33,  3133,\n",
      "          4847,    80,    13,     9,  8056,    16,    21,    16,    28,     6,\n",
      "          2367, 16977,   838,    16, 19307, 28584,     7,     1,    14,  1397,\n",
      "         28468,   790,   269, 28639, 30028,     7,    58,   790, 15743,   306,\n",
      "            40,     9, 26234,  6740,     7,  8093,    13,  1356,    62,  1058,\n",
      "          2992, 11218,    38, 12653,  2375,     9,   306,    14,  3596,    12,\n",
      "          6918, 28469,  3721,    40, 20138,    11,    34,     5,    75, 11218,\n",
      "             6,    36,  7731,  1989,     7,    28,   651,    34, 11181,     5,\n",
      "          1568,  6309,    14,   306,     5,    45,    11,  3596,    18,  1058,\n",
      "          2992,     8,    59,   462,    14,  1325,     5,    45,    11,    63,\n",
      "         13690,  9039, 28462,   335,    14,  1450,    18,     5,    65,  6172,\n",
      "          4053, 28869,    11, 24607,    16,    33,     5,    14,  5008,     7,\n",
      "          1577,    16,  1820,    16,    38,    36,  1040,     7, 13833,    14,\n",
      "            80,    40,  4755,    12,  6918, 28469,  3721,    38,    13, 12653,\n",
      "          2375,     9, 11213, 28504,     8, 10502,  5079,    14, 25266,    15,\n",
      "            16,    33, 23146,    75,     8,  1450,    14,    33,   594,     7,\n",
      "           223, 28781,    12,   319,    11,  4580,   969,    28,    33,     8,\n",
      "           962,  1450,    14,   150, 28502, 21918,    15,    16,     9, 10502,\n",
      "           335,     5,  2502,     5,  1738,     8,  1411,     9,   306,     5,\n",
      "           625,   124,     7,  6740,     7,    58,    16,     6, 12614,     5,\n",
      "          4605, 28614,    11, 10357, 28844,     6,   306,     5, 27348,  6199,\n",
      "            50, 21265,    13, 12004, 28468,    16,     9,  4543, 28458,  3635,\n",
      "           205,    29,  2935,  1529,     5,  1450,    13,  1495,    84, 28461,\n",
      "           312, 11181,     5,    45,     6,  1778, 10715, 28827,    13,   306,\n",
      "            28,   375,     5,   969,     5, 12050,     7,  5183,   790,     9,\n",
      "           203,    80,    13,  7105,     5,    75,    14,     8,  6675,    11,\n",
      "            34,    13,   306,   687,   278,  4937,   332,   139,     8,   755,\n",
      "         29546, 28545, 28527,   306,     5,    45,    11,   680,    16,     6,\n",
      "          2198,    28,  6175,    28,   319,     7,  6840,    80,    45,     9,\n",
      "          3654,    28,    14,    52,   559,     9,  1903,    14,    31,  3635,\n",
      "           205,     8,    36,  1359,     9, 20138,     5, 12966, 12735,    10,\n",
      "            38,   140,     5,     9, 19852,  7803,  3330,     5,  3834,  3464,\n",
      "            23,  2526,   573, 21096,   306,     5,  4443,  9398,    28,    15,\n",
      "            10,    15,     6,   594, 12455,    13, 16841, 28449,   900,    28,\n",
      "            63,  3654,    13,  5359,   118,   517,    10,     5,    29,    65,\n",
      "             9,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]])}}\n"
     ]
    }
   ],
   "source": [
    "# データセットのサマリーを確認\n",
    "print(f\"Number of samples: {len(row_dataset)}\")\n",
    "print(f\"Sample 0: {row_dataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "train_ratio = 0.8\n",
    "valid_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "train_dataset_num = int(len(row_dataset) * train_ratio)\n",
    "valid_dataset_num = int(len(row_dataset) * valid_ratio)\n",
    "test_dataset_num = len(row_dataset) - train_dataset_num - valid_dataset_num\n",
    "\n",
    "train_dataset = row_dataset[:train_dataset_num]\n",
    "valid_dataset = row_dataset[train_dataset_num:train_dataset_num + valid_dataset_num]\n",
    "test_dataset = row_dataset[train_dataset_num + valid_dataset_num:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "lr = 1e-5\n",
    "optimizer_parameters = model.parameters()\n",
    "optimizer = torch.optim.Adam(optimizer_parameters, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/5893 [00:23<1:41:50,  1.04s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m output_labels\u001b[38;5;241m.\u001b[39mappend(output_label)\n\u001b[1;32m     20\u001b[0m correct_labels\u001b[38;5;241m.\u001b[39mappend(labels)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "model.train()\n",
    "losses = []\n",
    "output_labels = []\n",
    "correct_labels = []\n",
    "for data in tqdm(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    input_ids = data[\"inputs\"][\"input_ids\"].squeeze(1)\n",
    "    attention_mask = data[\"inputs\"][\"attention_mask\"].squeeze(1)\n",
    "    token_type_ids = data[\"inputs\"][\"token_type_ids\"].squeeze(1)\n",
    "    labels = data[\"label\"]\n",
    "\n",
    "    model_output = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
    "    logit = model_output.logits\n",
    "    loss = model_output.loss\n",
    "    output_label = torch.argmax(logit, dim=1)\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    output_labels.append(output_label)\n",
    "    correct_labels.append(labels)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2を触ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
