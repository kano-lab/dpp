{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Livedoorニュースコーパスを用いたニューストピック分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### タスクの説明\n",
    "LiveDoorニュースコーパスを用いて、ニュース記事のトピック分類を行います。  \n",
    "本資料ではすでに加工済みのデータを利用しています。  \n",
    "元データのダウンドードは[こちらから](https://www.rondhuit.com/download.html)行えます。  \n",
    "\n",
    "このコーパスは各記事がどのトピックに属するかがラベル付けされています。\n",
    "このコーパスに含まれるトピックは以下の通りです。\n",
    "- トピックニュース\n",
    "- Sports Watch\n",
    "- ITライフハック\n",
    "- 家電チャンネル\n",
    "- MOVIE ENTER\n",
    "- 独女通信\n",
    "- エスマックス\n",
    "- livedoor HOMME\n",
    "- Peachy\n",
    "\n",
    "今回実装するタスクは、ニュース記事の本文から上記の九つのトピックのうちどれに属するかを予測するマルチクラス分類です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUが複数台搭載されている実行環境の場合、以下の環境変数を設定することで、使用するGPUを指定できます\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: fugashi in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (1.3.2)\n",
      "Requirement already satisfied: ipadic in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
      "Requirement already satisfied: six>=1.5 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /disk/ssd14tc/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリのインストール\n",
    "# NOTE: 仮想環境が適切に構築されていることを事前に確認して下さい\n",
    "!pip install pandas transformers torch fugashi ipadic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbaba/dev/python/dpp2024/part3/practice/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# seed値の設定\n",
    "from transformers import set_seed\n",
    "seed = 42\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=9, bias=True)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking', num_labels=num_labels)\n",
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Livedoorニュースコーパスの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 0, 'category': 'movie-enter'}, {'label': 1, 'category': 'peachy'}, {'label': 2, 'category': 'livedoor-homme'}, {'label': 3, 'category': 'kaden-channel'}, {'label': 4, 'category': 'dokujo-tsushin'}, {'label': 5, 'category': 'sports-watch'}, {'label': 6, 'category': 'smax'}, {'label': 7, 'category': 'it-life-hack'}, {'label': 8, 'category': 'topic-news'}]\n",
      "num_labels: 9\n"
     ]
    }
   ],
   "source": [
    "with open(\"./content/categories.json\",\"r\") as f:\n",
    "    d = f.read()\n",
    "    import json\n",
    "    categories = json.loads(d)\n",
    "num_labels = len(categories)\n",
    "print(categories)\n",
    "print(f\"num_labels: {num_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating train dataset...(this may take a while)\n",
      "creating valid dataset...\n",
      "creating test dataset...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"./content/train.csv\")\n",
    "df_valid = pd.read_csv(\"./content/valid.csv\")\n",
    "df_test = pd.read_csv(\"./content/test.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# tokenizerの読み込み\n",
    "from transformers import BertJapaneseTokenizer\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained('cl-tohoku/bert-base-japanese-whole-word-masking')\n",
    "\n",
    "# モデルの最大入力トークン数\n",
    "max_length = tokenizer.model_max_length\n",
    "print(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 今回用意されたcsvの形式が読み込まれたdata frameからtokenize後のデータセットを作成する関数を定義\n",
    "import random\n",
    "def create_dataset(df):\n",
    "    dataset = []\n",
    "    for i in range(len(df)):\n",
    "        label = df.iloc[i, 0]\n",
    "        text = df.iloc[i, 4]\n",
    "        if label == \"9\" & random.randint(1, 10) > 1:\n",
    "            continue\n",
    "        dataset.append({\n",
    "            \"label\": label,\n",
    "            \"text\": text,\n",
    "            \"encoding\": tokenizer(text, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "        })\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み込んだデータフレームから１レコードが辞書型として格納されている配列を作成\n",
    "print(\"creating train dataset...(this may take a while)\")\n",
    "train_dataset = create_dataset(df_train)\n",
    "print(\"creating valid dataset...\")\n",
    "valid_dataset = create_dataset(df_valid)\n",
    "print(\"creating test dataset...\")\n",
    "test_dataset = create_dataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5893\n",
      "Sample 0: {'text': '動物好きなアナタに！ iPhoneを動物図鑑にしてくれるアプリ【iPhoneでチャンスを掴め】子供の頃、野生の動物を紹介するテレビ番組にかじりついていたなんて人いらっしゃいませんか？\\u3000眺めているだけでも楽しい動物図鑑のアプリを紹介します。こんな人におすすめ：動物について英語で学びたい人、動物の写真を見たい人こんなときにおすすめ：動物について知りたいとき、動物の知識が欲しいときアプリ名：Animal Kingdom for iPhoneカテゴリ：教育価格：無料「子どもの頃、動物図鑑を飽きずにずっと眺めていた」「野生の動物を紹介するテレビは欠かさず見ていた」という方はいらっしゃいませんか？\\u3000そんな方におすすめのアプリです。動物図鑑がiPhoneアプリになりました。すべて英語ですが、眺めているだけでも十分に楽しめます。お子様でも楽しめるアプリです。ほら！動物の画像がこんなにたくさん！\\u3000好きな画像を選びましょう。すると動物の説明が！\\u3000英語ですが「サイズ」、「寿命」、「ライフスタイル」など、分かりやすくなっていますので英語の勉強にもなりますね。図鑑を一通り眺め終わったら、クイズに挑戦してみましょう！もちろん、名前で検索もできます。動物のスペルを知っていますか？\\u3000さらに動物の画像は、加工して保存したり、あるいは直接メールに添付できます。\\u3000動物好きな人にはたまらないアプリですね。■RainbowApps - iPhoneアプリ開発を学ぶなら1000人が受講したEagleが運営する東京校が一番！■成長率 888% 毎日 50万台増える Androidアプリに参入しよう。Androidマスターコース■人気のAngryBirds風アプリやスーパーマリオ風アプリが簡単に作れちゃう。ゲームアプリコース■iPhoneの日米人気アプリランキングをチェックするからRainbowApps■RainbowAppsの記事をもっと読む', 'label': 7, 'input_ids': {'input_ids': tensor([[    2,  2056,  3596,    18,  1742, 28502,     7,   679, 18060,    11,\n",
      "          2056, 17928,     7,    15,    16,  8009,  4437,  9680, 18060,    12,\n",
      "         10322,    11, 11401, 28506,  9594,  1803,     5,   807,     6,  8452,\n",
      "             5,  2056,    11,  1951,    34,   571,   486,     7, 19234, 14320,\n",
      "         28457,    16,    21,    10, 15060,    53, 24904, 28468,  7156, 28457,\n",
      "          6769,  1058,    29,  2935, 20974,    16,    33,   687,   962, 19835,\n",
      "          2056, 17928,     5,  4437,    11,  1951,    15,  2610,     8, 12272,\n",
      "            53,     7,    73, 28484, 28484, 28506,   266,  2056,   362,  1543,\n",
      "            12,  4660,  1549,    53,     6,  2056,     5,  1925,    11,   212,\n",
      "          1549,    53, 12272,   900,     7,    73, 28484, 28484, 28506,   266,\n",
      "          2056,   362,  4534,  1549,   900,     6,  2056,     5,  4125,    14,\n",
      "         10928,   900,  4437,   125,   266,  3090, 20427, 28595, 19841, 28683,\n",
      "          1393,  1690, 18060, 17672,   266,   890,  3225,   266,  4691,    36,\n",
      "          5465,     5,   807,     6,  2056, 17928,    11, 26373,   255,     7,\n",
      "         10027, 20974,    16,    21,    10,    38,    36,  8452,     5,  2056,\n",
      "            11,  1951,    34,   571,     9, 20059, 28475,   255,   212,    16,\n",
      "            21,    10,    38,   140,   283,     9, 24904, 28468,  7156, 28457,\n",
      "          6769,  1058,    29,  2935,  4799,   283,     7,    73, 28484, 28484,\n",
      "         28506,     5,  4437,  2992,     8,  2056, 17928,    14, 18060,  4437,\n",
      "             7,   297,  3913,    10,     8,  1520,  1543,  2992,    14,     6,\n",
      "         20974,    16,    33,   687,   962,  4030,     7,  4613, 28506,  2610,\n",
      "             8,    73, 28601, 28857,   962, 12932,  4437,  2992,     8,   232,\n",
      "         28469,   679,  2056,     5,  4845,    14, 12272, 28446, 12959,   679,\n",
      "          3596,    18,  4845,    11, 11681, 17015,   205,     8, 10556,  2056,\n",
      "             5,  2280,    14,   679,  1543,  2992,    14,    36,  4401,    38,\n",
      "             6,    36, 10827,    38,     6,    36,  6890, 14606,    38,    64,\n",
      "             6, 14604,  6391,    58,    16,    21,  2610,   947,  1543,     5,\n",
      "          8192,     7,    28,   297,  2610,  1852,     8, 17928,    11,    52,\n",
      "           939, 20974,  2764,  3318,     6,  6455,     7,  3073,    15,    16,\n",
      "           546, 17015,   205,   679,  8871,     6,  1381,    12,  8585,    28,\n",
      "           203,  2610,     8,  2056,     5, 23765,    11,  4021,    16,    21,\n",
      "          2610,    29,  2935,   604,  2056,     5,  4845,     9,     6,  5071,\n",
      "            15,    16,  3006,    15,   790,     6,  1511,  2031,  5589,     7,\n",
      "         17507,   203,  2610,     8,  2056,  3596,    18,    53,     7,     9,\n",
      "          6918, 28469,  3721,  4437,  2992,  1852,     8, 25035, 27935,   361,\n",
      "          9736, 29078, 28577,  6896, 28589,    61, 18060,  4437,   530,    11,\n",
      "          5290,   737,  3371,    53,    14, 15620,    15,    10,   500,  2535,\n",
      "           944,    14,  1460,    34,   391,  1292,    14,  4749,   679, 31407,\n",
      "          2473,   786,  5172, 28501,   648,  3904,  1241,   429,   551, 11701,\n",
      "         14400,  4437,     7,  7397,  2132,   205,     8, 14400,  5839,  2919,\n",
      "         25035,  1571,     5,  3090, 10690, 28825, 28687, 20850, 28589,   995,\n",
      "          4437,    49,  2002, 10194,   995,  4437,    14,  5880,     7, 28188,\n",
      "          3051, 28489,     8,   733, 16422,  6993, 25035, 18060,     5,    32,\n",
      "           885,  1571,  4437, 23342,    11,  9398,    34,    40, 27935,   361,\n",
      "          9736, 29078, 28577,  6896, 28589, 25035, 27935,   361,  9736, 29078,\n",
      "         28577,  6896, 28589,     5,  2622,    11,  8065,  9010,     3,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}}\n"
     ]
    }
   ],
   "source": [
    "# データセットを確認\n",
    "print(f\"Number of samples: {len(train_dataset)}\")\n",
    "print(f\"Sample 0: {train_dataset[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5893\n",
      "Number of validation samples: 736\n",
      "Number of test samples: 738\n"
     ]
    }
   ],
   "source": [
    "# Dataloaderの作成\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 64  # Hyperparameter\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(valid_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "lr = 1e-5 # Hyperparameter\n",
    "optimizer_parameters = model.parameters()\n",
    "optimizer = torch.optim.Adam(optimizer_parameters, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 学習を行うデバイスを設定\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start!!!\n",
      "########### 1 Epochs ###########\n",
      "Step 18 / 92, Last Loss 2.0047366619110107, Valid Accuracy 0.45108695652173914\n",
      "Step 36 / 92, Last Loss 1.5418059825897217, Valid Accuracy 0.625\n",
      "Step 54 / 92, Last Loss 1.1709026098251343, Valid Accuracy 0.7567934782608695\n",
      "Step 72 / 92, Last Loss 0.957701563835144, Valid Accuracy 0.7717391304347826\n",
      "Step 90 / 92, Last Loss 0.8178668022155762, Valid Accuracy 0.8233695652173914\n",
      "########### 2 Epochs ###########\n",
      "Step 108 / 92, Last Loss 0.6956350803375244, Valid Accuracy 0.8586956521739131\n",
      "Step 126 / 92, Last Loss 0.4833647906780243, Valid Accuracy 0.8967391304347826\n",
      "Step 144 / 92, Last Loss 0.35873493552207947, Valid Accuracy 0.8953804347826086\n",
      "Step 162 / 92, Last Loss 0.2874962091445923, Valid Accuracy 0.9198369565217391\n",
      "Step 180 / 92, Last Loss 0.37805742025375366, Valid Accuracy 0.9089673913043478\n",
      "########### 3 Epochs ###########\n",
      "Step 198 / 92, Last Loss 0.2096950262784958, Valid Accuracy 0.9429347826086957\n",
      "Step 216 / 92, Last Loss 0.31642088294029236, Valid Accuracy 0.9415760869565217\n",
      "Step 234 / 92, Last Loss 0.23263482749462128, Valid Accuracy 0.9442934782608695\n",
      "Step 252 / 92, Last Loss 0.14764919877052307, Valid Accuracy 0.9483695652173914\n",
      "Step 270 / 92, Last Loss 0.09113892912864685, Valid Accuracy 0.9429347826086957\n",
      "train finish!!!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "losses = []\n",
    "\n",
    "epoch_num = 3 # Hyperparameter\n",
    "\n",
    "step_num = 1\n",
    "epochs = 1\n",
    "\n",
    "last_loss = float('inf')\n",
    "loss_threshold = 0.02 # Hyperparameter\n",
    "\n",
    "valid_step_period = len(train_dataloader) // 5\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "print(\"train start!!!\")\n",
    "for _ in range(epoch_num):\n",
    "    print(f'########### Epoch {epochs} ###########')\n",
    "    # train step\n",
    "    for data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = data[\"encoding\"][\"input_ids\"].squeeze(1).to(device)\n",
    "        attention_mask = data[\"encoding\"][\"attention_mask\"].squeeze(1).to(device)\n",
    "        token_type_ids = data[\"encoding\"][\"token_type_ids\"].squeeze(1).to(device)\n",
    "        labels = data[\"label\"].to(device)\n",
    "    \n",
    "        model_output = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)\n",
    "        logit = model_output.logits\n",
    "        loss = model_output.loss\n",
    "        output_label = torch.argmax(logit, dim=1)\n",
    "    \n",
    "        losses.append(loss.item())\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        last_loss = loss.item()\n",
    "        step_num += 1\n",
    "    \n",
    "        # validation step\n",
    "        if step_num % valid_step_period == 0:\n",
    "            valid_output_labels = []\n",
    "            valid_correct_labels = []\n",
    "            for data in valid_dataloader:\n",
    "                labels = data[\"label\"].to(device)\n",
    "                \n",
    "                model_output = model(**{k: v.squeeze(1).to(device) for k, v in data[\"encoding\"].items()}, labels=labels)\n",
    "                # モデルの最終層の出力\n",
    "                logit = model_output.logits\n",
    "                # モデルの最終層の出力が最も高いラベルを予測ラベルとする\n",
    "                output_label = torch.argmax(logit, dim=1)\n",
    "\n",
    "                valid_output_labels.append(output_label)\n",
    "                valid_correct_labels.append(labels)\n",
    "\n",
    "            # accuracyの算出：モデルの出力ラベルと正解ラベルが一致している数を全データ数で割った値を算出\n",
    "            valid_accuracy = torch.sum(torch.cat(valid_output_labels) == torch.cat(valid_correct_labels)).item() / len(valid_dataset)\n",
    "            print(f\"Step {step_num} / {len(train_dataloader)}, Last Loss {last_loss}, Valid Accuracy {valid_accuracy}\")\n",
    "            # モデルを学習モードに戻す\n",
    "            model.train()\n",
    "\n",
    "        # early stopping\n",
    "        if last_loss < loss_threshold:\n",
    "            print(\"Loss is less than threshold!\")\n",
    "            break\n",
    "    epochs += 1\n",
    "    step = 0\n",
    "print(\"train finish!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 738/738 [00:06<00:00, 109.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# test step\n",
    "test_correct_num = 0\n",
    "test_total_num = len(test_dataset)\n",
    "\n",
    "model.eval()\n",
    "for data in tqdm(test_dataloader):\n",
    "    labels = data[\"label\"].to(device)\n",
    "\n",
    "    model_output = model(**{k: v.squeeze().to(device) for k,v in data[\"encoding\"].items()}, labels=labels)\n",
    "    logit = model_output.logits\n",
    "    output_label = torch.argmax(logit, dim=1)\n",
    "\n",
    "    test_correct_num += torch.sum(output_label == labels).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct samples | total samples : 703 | 738\n",
      "Accuracy: 0.9525745257452575\n"
     ]
    }
   ],
   "source": [
    "accuracy = test_correct_num / test_total_num\n",
    "print(f\"correct samples | total samples : {test_correct_num} | {test_total_num}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの保存\n",
    "model_dir = \"./content/model/\"\n",
    "model_full_path = model_dir + \"model.pth\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "torch.save(model.state_dict(), model_full_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
